[INFO] [launch]: All log files can be found below /root/.ros/log/2023-02-17-06-18-56-425385-5e34e48a91ce-8187
[INFO] [launch]: Default logging verbosity is set to INFO
[INFO] [pipeline_with_params-1]: process started with pid [8189]
[pipeline_with_params-1] OpenVINO: OpenVINO Runtime
[pipeline_with_params-1]     Version : 2022.3.0
[pipeline_with_params-1]     Build   : 2022.3.0-9052-9752fafe8eb-releases/2022/3
[pipeline_with_params-1] 
[pipeline_with_params-1] [34m[ INFO ] Config File Path =/root/catkin_ws/install/dynamic_vino_sample/share/dynamic_vino_sample/param/pipeline_reidentification.yaml[0m
[pipeline_with_params-1] [34m[ INFO ] Pipeline size: 1[0m
[pipeline_with_params-1] [34m[ INFO ] Inferences size: 2[0m
[pipeline_with_params-1] [33m[ WARNING ] invalid node; this may result from using a map iterator as a sequence iterator, or vice-versa[0m
[pipeline_with_params-1] [34m[ INFO ] Inference Params:name=ObjectDetection[0m
[pipeline_with_params-1] [33m[ WARNING ] invalid node; this may result from using a map iterator as a sequence iterator, or vice-versa[0m
[pipeline_with_params-1] [33m[ WARNING ] invalid node; this may result from using a map iterator as a sequence iterator, or vice-versa[0m
[pipeline_with_params-1] [34m[ INFO ] Inference Params:name=PersonReidentification[0m
[pipeline_with_params-1] [34m[ INFO ] Pipeline Params:name=object[0m
[pipeline_with_params-1] [33m[ WARNING ] invalid node; this may result from using a map iterator as a sequence iterator, or vice-versa[0m
[pipeline_with_params-1] [33m[ WARNING ] invalid node; this may result from using a map iterator as a sequence iterator, or vice-versa[0m
[pipeline_with_params-1] [33m[ WARNING ] invalid node; this may result from using a map iterator as a sequence iterator, or vice-versa[0m
[pipeline_with_params-1] [33m[ WARNING ] invalid node; this may result from using a map iterator as a sequence iterator, or vice-versa[0m
[pipeline_with_params-1] [34m[ INFO ] --------parameters DUMP---------------------[0m
[pipeline_with_params-1] [34m[ INFO ] Pipeline: object[0m
[pipeline_with_params-1] [34m[ INFO ] 	Inputs: Image, [0m
[pipeline_with_params-1] [34m[ INFO ] 	Outputs: RosTopic, [0m
[pipeline_with_params-1] [34m[ INFO ] 	Inferences: [0m
[pipeline_with_params-1] [34m[ INFO ] 		Name: ObjectDetection[0m
[pipeline_with_params-1] [34m[ INFO ] 		Model: /opt/openvino_toolkit/models/intel/person-detection-retail-0013/FP32/person-detection-retail-0013.xml[0m
[pipeline_with_params-1] [34m[ INFO ] 		Engine: CPU[0m
[pipeline_with_params-1] [34m[ INFO ] 		Label: to/be/set/xxx.labels[0m
[pipeline_with_params-1] [34m[ INFO ] 		Batch: 1[0m
[pipeline_with_params-1] [34m[ INFO ] 		Confidence_threshold: 0.5[0m
[pipeline_with_params-1] [34m[ INFO ] 		Enable_roi_constraint: 1[0m
[pipeline_with_params-1] [34m[ INFO ] 		Name: PersonReidentification[0m
[pipeline_with_params-1] [34m[ INFO ] 		Model: /opt/openvino_toolkit/models/intel/person-reidentification-retail-0277/FP32/person-reidentification-retail-0277.xml[0m
[pipeline_with_params-1] [34m[ INFO ] 		Engine: CPU[0m
[pipeline_with_params-1] [34m[ INFO ] 		Label: to/be/set/xxx.labels[0m
[pipeline_with_params-1] [34m[ INFO ] 		Batch: 1[0m
[pipeline_with_params-1] [34m[ INFO ] 		Confidence_threshold: 0.7[0m
[pipeline_with_params-1] [34m[ INFO ] 		Enable_roi_constraint: 0[0m
[pipeline_with_params-1] [34m[ INFO ] 	Connections: [0m
[pipeline_with_params-1] [34m[ INFO ] 		Image->ObjectDetection[0m
[pipeline_with_params-1] [34m[ INFO ] 		ObjectDetection->PersonReidentification[0m
[pipeline_with_params-1] [34m[ INFO ] 		PersonReidentification->RosTopic[0m
[pipeline_with_params-1] [34m[ INFO ] Common:[0m
[pipeline_with_params-1] [34m[ INFO ] 	camera_topic: [0m
[pipeline_with_params-1] [34m[ INFO ] 	custom_cpu_library: [0m
[pipeline_with_params-1] [34m[ INFO ] 	custom_cldnn_library: [0m
[pipeline_with_params-1] [34m[ INFO ] 	enable_performance_count: 0[0m
[pipeline_with_params-1] [34m[ INFO ] Parsing InputDvice: Image[0m
[pipeline_with_params-1] [34m[ INFO ]  ... Adding one Input device: Image[0m
[pipeline_with_params-1] [34m[ INFO ] Adding Input Device into Pipeline: Image[0m
[pipeline_with_params-1] [34m[ INFO ] Adding connection into pipeline:[<-->Image][0m
[pipeline_with_params-1] [34m[ INFO ] Parsing Output: RosTopic[0m
[pipeline_with_params-1] [34m[ INFO ]  ... Adding one Output: RosTopic[0m
[pipeline_with_params-1] [34m[ INFO ] Parsing Inference: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] for test in createObjectDetection()[0m
[pipeline_with_params-1] [32m[ DEBUG ] TESTING: in ObjectDetectionSSDModel[0m
[pipeline_with_params-1] [32m[ DEBUG ] for test in createObjectDetection(), Created SSDModel[0m
[pipeline_with_params-1] [32m[ DEBUG ] for test in createObjectDetection(), before modelInit()[0m
[pipeline_with_params-1] [34m[ INFO ] Loading network files/opt/openvino_toolkit/models/intel/person-detection-retail-0013/FP32/person-detection-retail-0013.xml[0m
[pipeline_with_params-1] [34m[ INFO ] to/be/set/xxx.labels[0m
[pipeline_with_params-1] [34m[ INFO ] Batch size is set to  1[0m
[pipeline_with_params-1] [34m[ INFO ] Checking INPUTs for model /opt/openvino_toolkit/models/intel/person-detection-retail-0013/FP32/person-detection-retail-0013.xml[0m
[pipeline_with_params-1] [34m[ INFO ] Checking OUTPUTs for model /opt/openvino_toolkit/models/intel/person-detection-retail-0013/FP32/person-detection-retail-0013.xml[0m
[pipeline_with_params-1] [34m[ INFO ] Checking Object Detection output ... Name=detection_out[0m
[pipeline_with_params-1] [34m[ INFO ] max proposal count is: 200[0m
[pipeline_with_params-1] [34m[ INFO ] ----Attributes for Model /opt/openvino_toolkit/models/intel/person-detection-retail-0013/FP32/person-detection-retail-0013.xml----[0m
[pipeline_with_params-1] [34m[ INFO ] | model_name: /opt/openvino_toolkit/models/intel/person-detection-retail-0013/FP32/person-detection-retail-0013.xml[0m
[pipeline_with_params-1] [34m[ INFO ] | max_proposal_count: 200[0m
[pipeline_with_params-1] [34m[ INFO ] | object_size: 7[0m
[pipeline_with_params-1] [34m[ INFO ] | input_height: 320[0m
[pipeline_with_params-1] [34m[ INFO ] | input_width: 544[0m
[pipeline_with_params-1] [34m[ INFO ] | input_names: [0m
[pipeline_with_params-1] [34m[ INFO ] |    input-->data[0m
[pipeline_with_params-1] [34m[ INFO ] | output_names: [0m
[pipeline_with_params-1] [34m[ INFO ] |    output-->detection_out[0m
[pipeline_with_params-1] [34m[ INFO ] --------------------------------[0m
[pipeline_with_params-1] [34m[ INFO ] This model is SSDNet-like, Layer Property updated![0m
[pipeline_with_params-1] [32m[ DEBUG ] for test in createObjectDetection(), before loadNetwork[0m
[pipeline_with_params-1] [32m[ DEBUG ] for test in createObjectDetection(), OK[0m
[pipeline_with_params-1] [34m[ INFO ]  ... Adding one Inference: ObjectDetection[0m
[pipeline_with_params-1] [34m[ INFO ] Parsing Inference: PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] for test in createPersonReidentification()[0m
[pipeline_with_params-1] [34m[ INFO ] Loading network files/opt/openvino_toolkit/models/intel/person-reidentification-retail-0277/FP32/person-reidentification-retail-0277.xml[0m
[pipeline_with_params-1] [34m[ INFO ] to/be/set/xxx.labels[0m
[pipeline_with_params-1] [34m[ INFO ] Batch size is set to  1[0m
[pipeline_with_params-1] [34m[ INFO ] Checking Inputs for Model/opt/openvino_toolkit/models/intel/person-reidentification-retail-0277/FP32/person-reidentification-retail-0277.xml[0m
[pipeline_with_params-1] [34m[ INFO ] Reidentification model initialized[0m
[pipeline_with_params-1] [32m[ DEBUG ] for test in createPersonReidentification(), before loadNetwork[0m
[pipeline_with_params-1] [32m[ DEBUG ] for test in createPersonReidentification(), OK[0m
[pipeline_with_params-1] [34m[ INFO ]  ... Adding one Inference: PersonReidentification[0m
[pipeline_with_params-1] [34m[ INFO ] Updating connections ...[0m
[pipeline_with_params-1] [34m[ INFO ] Checking connection into pipeline:[Image(1)<-->ObjectDetection(2)][0m
[pipeline_with_params-1] [34m[ INFO ] Adding connection into pipeline:[Image<-->ObjectDetection][0m
[pipeline_with_params-1] [34m[ INFO ] Checking connection into pipeline:[ObjectDetection(2)<-->PersonReidentification(2)][0m
[pipeline_with_params-1] [34m[ INFO ] Adding connection into pipeline:[ObjectDetection<-->PersonReidentification][0m
[pipeline_with_params-1] [34m[ INFO ] Checking connection into pipeline:[PersonReidentification(2)<-->RosTopic(3)][0m
[pipeline_with_params-1] [34m[ INFO ] Adding connection into pipeline:[PersonReidentification<-->RosTopic][0m
[pipeline_with_params-1] [34m[ INFO ] One Pipeline Created![0m
[pipeline_with_params-1]  --> Image
[pipeline_with_params-1] Image --> ObjectDetection
[pipeline_with_params-1] ObjectDetection --> PersonReidentification
[pipeline_with_params-1] PersonReidentification --> RosTopic
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> PersonReidentification[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...handleOutput[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: in Pipeline run process...[0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Enqueue for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] add input image to blob: data[0m
[pipeline_with_params-1] [32m[ DEBUG ] Convert input image to blob: DONE![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: Submit Infer request for detection: ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
[pipeline_with_params-1] [32m[ DEBUG ] DEBUG: align inference process, waiting until all inferences done![0m
[pipeline_with_params-1] [32m[ DEBUG ] Hello callback ----> ObjectDetection[0m
[pipeline_with_params-1] [32m[ DEBUG ] fetching Infer Resulsts from the given SSD model[0m
[pipeline_with_params-1] [32m[ DEBUG ] Fetching Detection Results ...[0m
[pipeline_with_params-1] [32m[ DEBUG ] Analyzing Detection results...[0m
[pipeline_with_params-1] [32m[ DEBUG ] MaxProprosalCount=200, ObjectSize=7[0m
[pipeline_with_params-1] [32m[ DEBUG ] Async Inference started![0m
